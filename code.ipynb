{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxYDtZLDKr1b"
      },
      "source": [
        "###Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4fNqvDWrLhq",
        "outputId": "30372463-f856-4ed1-ff7a-0fb7698d2894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of images in a training set is:  50176\n",
            "The number of images in a test set is:  10240\n",
            "The number of batches per epoch is:  98\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Defining data preprocessing transformations\n",
        "'''\n",
        "transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "'''\n",
        "transformations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Setting the batch size\n",
        "batch_size = 512\n",
        "number_of_labels = 100  # CIFAR-100 has 100 categories\n",
        "\n",
        "# Load the CIFAR-100 training set\n",
        "train_set = CIFAR100(root=\"./data\", train=True, transform=transformations, download=True)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "print(\"The number of images in a training set is: \", len(train_loader) * batch_size)\n",
        "\n",
        "# Load the CIFAR-100 test set\n",
        "test_set = CIFAR100(root=\"./data\", train=False, transform=transformations, download=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "print(\"The number of images in a test set is: \", len(test_loader) * batch_size)\n",
        "print(\"The number of batches per epoch is: \", len(train_loader))\n",
        "\n",
        "# CIFAR-100 categories\n",
        "classes = (\n",
        "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle',\n",
        "    'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle',\n",
        "    'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
        "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard',\n",
        "    'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain',\n",
        "    'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree',\n",
        "    'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket',\n",
        "    'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider',\n",
        "    'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor',\n",
        "    'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE_bVADxK6Zx"
      },
      "source": [
        "###Define a CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yck5-25Rs96i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define a CNN\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        # The first convolutional layer：3 -> 32\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # The second convolutional layer：32 -> 64\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # The first Pooling Layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # 32x32 -> 16x16\n",
        "\n",
        "        # The third convolutional layer：64 -> 128\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # The fourth convolutional layer：128 -> 256\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "        # The second Pooling Layer\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)  # 16x16 -> 8x8\n",
        "\n",
        "        # The fiveth convolutional layer：256 -> 512\n",
        "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "\n",
        "        # The third Pooling Layer\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)  # 8x8 -> 4x4\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc1 = nn.Linear(512 * 4 * 4, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 100)  # CIFAR-100\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)  # Pooling 16x16\n",
        "\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)  # Pooling 8x8\n",
        "\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x = self.pool3(x)  # Pooling 4x4\n",
        "\n",
        "        x = x.view(-1, 512 * 4 * 4)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)  # output 100 classes\n",
        "\n",
        "        return x\n",
        "\n",
        "# create model\n",
        "model = Network()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mARQ4R8ULCqm"
      },
      "source": [
        "###Define the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ9tcu-1s-6N"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "# define the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# loss_fn = nn.NLLLoss()\n",
        "# define an optimizer with Adam optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlxJ5aZsLHOi"
      },
      "source": [
        "###Define functions for model training, as well as functions for calculating training accuracy, test accuracy, saving models, and drawing graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ennnwZG4tBHy"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "import torch\n",
        "\n",
        "# Function to save the model\n",
        "def saveModel():\n",
        "    path = \"./myFirstModel.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "# function to calculate testing accuracy\n",
        "def testAccuracy():\n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            outputs = model(images.to(device))\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return accuracy\n",
        "\n",
        "# function to calculate training accuracy\n",
        "def trainAccuracy():\n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in train_loader:\n",
        "            images, labels = data\n",
        "            outputs = model(images.to(device))\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "    accuracy = (100 * accuracy / total)\n",
        "    return accuracy\n",
        "\n",
        "# define train function\n",
        "# we have three paramaters\n",
        "# num_epochs is about how much times do we need to train\n",
        "# patience is using for the early stopping mechanism\n",
        "# loss_threshold is also using for the early stopping mechanism\n",
        "def train(num_epochs, patience=5, loss_threshold=0.01):\n",
        "    # to record the best test accuracy\n",
        "    best_accuracy = 0.0\n",
        "    # to calculate how much continue epochs we don't have any improvement\n",
        "    no_improve_epochs = 0\n",
        "\n",
        "    # choose a device to train model\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Running device is\", device, \"device\")\n",
        "    model.to(device)\n",
        "\n",
        "    # record every epoch train accuracy\n",
        "    train_accuracies = []\n",
        "    # record every epoch test accuracy\n",
        "    test_accuracies = []\n",
        "    # record every epoch loss value\n",
        "    losses = []\n",
        "    # record how much epoch we run\n",
        "    run_epoch_num = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader, 0):\n",
        "            images = Variable(images.to(device))\n",
        "            labels = Variable(labels.to(device))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # calculate the avg loss value for every epoch\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "        # calculate the train accuracy and test accuracy\n",
        "        train_acc = trainAccuracy()\n",
        "        test_acc = testAccuracy()\n",
        "        print(f'For epoch {epoch+1}, Training Accuracy: {train_acc:.2f}%, Test Accuracy: {test_acc:.2f}%')\n",
        "\n",
        "        train_accuracies.append(train_acc)\n",
        "        test_accuracies.append(test_acc)\n",
        "\n",
        "        run_epoch_num += 1\n",
        "\n",
        "        # Early Stopping Mechanism: if we don't have any improvement in test accuracy. we will add one value in the variable of no_improve_epochs\n",
        "        if test_acc > best_accuracy:\n",
        "            saveModel()\n",
        "            best_accuracy = test_acc\n",
        "            # renew to calculate\n",
        "            no_improve_epochs = 0\n",
        "        else:\n",
        "            no_improve_epochs += 1\n",
        "\n",
        "        # the first stopping condition: if our variable value of no_improve_epochs equals or greater than the value we setting. we will break our trainning process\n",
        "        if no_improve_epochs >= patience:\n",
        "            print(f'Early stopping at epoch {epoch+1} due to no improvement in {patience} epochs.')\n",
        "            break\n",
        "\n",
        "        # the second stopping condition: if our loss value is less than the value we setting. we also will break the trainning process\n",
        "        if avg_loss < loss_threshold:\n",
        "            print(f'Training stopped at epoch {epoch+1} because loss {avg_loss:.4f} is below threshold {loss_threshold}.')\n",
        "            break\n",
        "\n",
        "    return train_accuracies, test_accuracies, losses, run_epoch_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO8ZYcaSSAIW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def make_photos(epoch_num, train_accuracies, test_accuracies, losses):\n",
        "  # data\n",
        "  epochs = list(range(1, epoch_num + 1))  # generate a list of integers from 1 to epoch_num\n",
        "\n",
        "  # creating the Figure and Axes\n",
        "  fig, ax1 = plt.subplots()\n",
        "\n",
        "  # draw the accuracy curve (left axis)\n",
        "  ax1.set_xlabel('Epoch')\n",
        "  ax1.set_ylabel('Accuracy', color='tab:blue')\n",
        "  ax1.plot(epochs, train_accuracies, 'o-', label='Train Accuracy', color='tab:blue')\n",
        "  ax1.plot(epochs, test_accuracies, 's-', label='Test Accuracy', color='tab:cyan')\n",
        "  ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
        "  ax1.set_xticks(epochs)  # only show integer epochs\n",
        "\n",
        "  step = max(1, epoch_num // 10)  # take a point every 10%\n",
        "  plt.xticks(epochs[::step])  # rotate 45 degrees to prevent overlap\n",
        "\n",
        "  ax1.legend(loc='upper left')\n",
        "\n",
        "  # create a second y-axis and plot the loss curve\n",
        "  ax2 = ax1.twinx()\n",
        "  ax2.set_ylabel('Loss', color='tab:red')\n",
        "  ax2.plot(epochs, losses, 'd-', label='Loss', color='tab:red')\n",
        "  ax2.tick_params(axis='y', labelcolor='tab:red')\n",
        "  ax2.legend(loc='upper right')\n",
        "\n",
        "  # set the title\n",
        "  plt.title('Training and Testing Accuracy & Loss Over Epochs')\n",
        "\n",
        "  # display the chart\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUmdVqd9LWRd"
      },
      "source": [
        "###Test a batch of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVOS-yD-tDjS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# function to show the images\n",
        "def imageshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    img = img.numpy()\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# function to test the model with a batch of images and show the labels predictions\n",
        "def testBatch():\n",
        "    # get batch of images from the test DataLoader\n",
        "    test_loader = DataLoader(test_set, batch_size=100, shuffle=False, num_workers=0)\n",
        "    images, labels = next(iter(test_loader))\n",
        "\n",
        "    # show all images as one image grid\n",
        "    imageshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "    # show the real labels on the screen\n",
        "    print('Real labels: ', ' '.join('%5s' % classes[labels[j]]\n",
        "                               for j in range(100)))\n",
        "\n",
        "    # let's see what if the model identifiers the  labels of those example\n",
        "    outputs = model(images)\n",
        "\n",
        "    # we got the probability for every 100 labels. The highest (max) probability should be correct label\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # let's show the predicted labels on the screen to compare with the real ones\n",
        "    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(100)))\n",
        "\n",
        "    # visualizing predictions vs actual labels\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(len(images)):\n",
        "        plt.subplot(10, 10, i + 1)  # arranging in 10x10 grid for 100 images\n",
        "        plt.imshow(np.transpose((images[i] / 2 + 0.5).numpy(), (1, 2, 0)))  # show each image\n",
        "        plt.title(f\"Real: {classes[labels[i]]}\\nPred: {classes[predicted[i]]}\", fontsize=6)\n",
        "        plt.axis('off')\n",
        "\n",
        "    # automatically adjust subplots to make space for titles\n",
        "    plt.subplots_adjust(hspace=1, wspace=1)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUfipiAgLkVC"
      },
      "source": [
        "###Main program entry file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr0OIfLOtN2-",
        "outputId": "7c2f6913-3ac0-443b-e4e3-6bb663ba289b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running device is cuda:0 device\n",
            "Epoch 1, Loss: 4.0098\n",
            "For epoch 1, Training Accuracy: 12.00%, Test Accuracy: 11.69%\n",
            "Epoch 2, Loss: 3.3302\n",
            "For epoch 2, Training Accuracy: 21.43%, Test Accuracy: 21.11%\n",
            "Epoch 3, Loss: 2.8327\n",
            "For epoch 3, Training Accuracy: 27.89%, Test Accuracy: 27.49%\n",
            "Epoch 4, Loss: 2.4977\n",
            "For epoch 4, Training Accuracy: 36.76%, Test Accuracy: 34.93%\n",
            "Epoch 5, Loss: 2.2426\n",
            "For epoch 5, Training Accuracy: 40.18%, Test Accuracy: 37.26%\n",
            "Epoch 6, Loss: 2.0705\n",
            "For epoch 6, Training Accuracy: 43.95%, Test Accuracy: 40.07%\n",
            "Epoch 7, Loss: 1.9160\n",
            "For epoch 7, Training Accuracy: 47.37%, Test Accuracy: 43.92%\n",
            "Epoch 8, Loss: 1.7961\n",
            "For epoch 8, Training Accuracy: 48.63%, Test Accuracy: 45.19%\n",
            "Epoch 9, Loss: 1.6874\n",
            "For epoch 9, Training Accuracy: 52.23%, Test Accuracy: 46.65%\n",
            "Epoch 10, Loss: 1.6146\n",
            "For epoch 10, Training Accuracy: 53.47%, Test Accuracy: 48.15%\n",
            "Epoch 11, Loss: 1.5168\n",
            "For epoch 11, Training Accuracy: 54.30%, Test Accuracy: 48.72%\n",
            "Epoch 12, Loss: 1.4437\n",
            "For epoch 12, Training Accuracy: 57.02%, Test Accuracy: 49.79%\n",
            "Epoch 13, Loss: 1.3754\n",
            "For epoch 13, Training Accuracy: 57.83%, Test Accuracy: 50.98%\n",
            "Epoch 14, Loss: 1.3160\n",
            "For epoch 14, Training Accuracy: 61.21%, Test Accuracy: 53.04%\n",
            "Epoch 15, Loss: 1.2677\n",
            "For epoch 15, Training Accuracy: 63.24%, Test Accuracy: 54.15%\n",
            "Epoch 16, Loss: 1.2068\n",
            "For epoch 16, Training Accuracy: 63.46%, Test Accuracy: 53.58%\n",
            "Epoch 17, Loss: 1.1528\n",
            "For epoch 17, Training Accuracy: 66.08%, Test Accuracy: 55.09%\n",
            "Epoch 18, Loss: 1.1049\n",
            "For epoch 18, Training Accuracy: 66.83%, Test Accuracy: 55.36%\n",
            "Epoch 19, Loss: 1.0528\n",
            "For epoch 19, Training Accuracy: 70.16%, Test Accuracy: 57.37%\n",
            "Epoch 20, Loss: 1.0084\n",
            "For epoch 20, Training Accuracy: 69.41%, Test Accuracy: 56.32%\n",
            "Epoch 21, Loss: 0.9692\n",
            "For epoch 21, Training Accuracy: 69.83%, Test Accuracy: 56.19%\n",
            "Epoch 22, Loss: 0.9318\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # build our model\n",
        "    epoch_num = 50\n",
        "    train_accuracies, test_accuracies, losses, run_epoch_num = train(epoch_num)\n",
        "    make_photos(run_epoch_num, train_accuracies, test_accuracies, losses)\n",
        "    print('Finished Training')\n",
        "\n",
        "    # test which classes performed well\n",
        "    testAccuracy()\n",
        "\n",
        "    # let's load the model we just created and test the accuracy per label\n",
        "    model = Network()\n",
        "    path = \"myFirstModel.pth\"\n",
        "    model.load_state_dict(torch.load(path))\n",
        "\n",
        "    # test with batch of images\n",
        "    testBatch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "PUmdVqd9LWRd"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}